### Script for the Slide: Comparative Analysis of Models

---

**Slide Title:** Comparative Analysis of Models

---

**Introduction (5-7 seconds):**
"Now, let’s analyze how the H2AN-BiLSTM model compares to other commonly used approaches in terms of accuracy. This table highlights the performance of several models in classifying software requirements."

---

**Point 1: Bag-of-Words and Word2Vec (10-15 seconds):**
"First, we have traditional models like Bag-of-Words, which achieves an accuracy of 92%, and Word2Vec, which falls behind at 87%. These models are limited in their ability to capture deep contextual relationships, particularly at the document and word levels."

---

**Point 2: BERT and DistilBERT (10-15 seconds):**
"Next, transformer-based models like BERT and DistilBERT improve performance, achieving accuracies of 91% and 90%, respectively. While they capture strong word-level semantics, they still lack the ability to combine global document-level insights effectively."

---

**Point 3: H2AN-BiLSTM (10-15 seconds):**
"Finally, our proposed hybrid model, H2AN-BiLSTM, outperforms all other approaches with an accuracy of 94.40%. This is achieved by integrating document-level semantics from Doc2Vec with word-level contextual embeddings from DistilBERT, enhanced by hierarchical attention and Bi-LSTM for sequential dependencies."

---

**Observations (5-7 seconds):**
"This comparative analysis clearly shows that combining Doc2Vec and DistilBERT in a hybrid model is highly effective, leveraging the strengths of both approaches while addressing their individual limitations."

---

**Transition (5 seconds):**
"With this strong comparative performance, let’s move on to discuss the broader implications and potential applications of this model."

---

This script keeps the comparison clear and emphasizes the strengths of the hybrid approach.
