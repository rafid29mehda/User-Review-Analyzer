{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "G1id8K6tjYlu",
        "outputId": "dd006094-35f3-468b-b25f-0459b1f6fc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-24b5a3d5-51c6-403c-b169-87c5ef32babb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-24b5a3d5-51c6-403c-b169-87c5ef32babb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final_corrected_fine_labeled_reviews.csv to final_corrected_fine_labeled_reviews (1).csv\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim transformers torch scikit-learn tqdm nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Doc2Vec\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "from huggingface_hub import hf_hub_download\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the uploaded CSV into a DataFrame\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "\n",
        "# Map 'RequirementType' to 'labels' (Functional: 1, Non-Functional: 0)\n",
        "label_mapping = {'F': 1, 'NF': 0}\n",
        "df['labels'] = df['RequirementType'].map(label_mapping)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lKKMkLlvrV-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize documents into sentences\n",
        "nltk.download('punkt')\n",
        "df['sentences'] = df['content'].apply(sent_tokenize)\n",
        "\n",
        "# Download and load the Doc2Vec model from Hugging Face\n",
        "model_path = hf_hub_download(repo_id=\"RafidMehda/doc2vec_model\", filename=\"doc2vec_model\")\n",
        "doc2vec_model = Doc2Vec.load(model_path)\n",
        "\n",
        "# Load pre-trained DistilBERT model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"RafidMehda/fined-distilBERT\")\n",
        "distilbert_model = AutoModel.from_pretrained(\"RafidMehda/fined-distilBERT\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdkyH66frWUv",
        "outputId": "b8b52c47-3662-4fc6-a6b0-ba0fa72eb453"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SvbOpE5rrWgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get Doc2Vec embeddings\n",
        "def get_doc2vec_embeddings(index):\n",
        "    doc2vec_emb = doc2vec_model.dv[str(index)]\n",
        "    return doc2vec_emb\n",
        "\n",
        "# Apply the function to extract Doc2Vec embeddings\n",
        "doc2vec_embeddings = [get_doc2vec_embeddings(i) for i in range(len(df))]\n",
        "\n",
        "# Function to get DistilBERT embeddings for sentences in a document\n",
        "def get_distilbert_sentence_embeddings(sentences):\n",
        "    sentence_embeddings = []\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "            last_hidden_state = outputs.last_hidden_state\n",
        "            pooled_embedding = torch.mean(last_hidden_state, dim=1)\n",
        "        sentence_embeddings.append(pooled_embedding.squeeze().numpy())\n",
        "    return sentence_embeddings\n",
        "\n",
        "# Apply the function to get DistilBERT embeddings for each document's sentences\n",
        "df['sentence_embeddings'] = df['sentences'].apply(get_distilbert_sentence_embeddings)\n"
      ],
      "metadata": {
        "id": "fA4FWBe8rXJM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d0jH3mhErXXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn_weights = nn.Parameter(torch.Tensor(hidden_dim, 1))\n",
        "        nn.init.xavier_uniform_(self.attn_weights)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        attn_scores = torch.tanh(torch.matmul(hidden_states, self.attn_weights)).squeeze(-1)\n",
        "        attn_weights = F.softmax(attn_scores, dim=1)\n",
        "        weighted_sum = torch.bmm(attn_weights.unsqueeze(1), hidden_states).squeeze(1)\n",
        "        return weighted_sum, attn_weights\n",
        "\n",
        "# Initialize the attention model\n",
        "sentence_attention = Attention(hidden_dim=768)\n",
        "\n",
        "# Apply attention mechanism\n",
        "sentence_attention_outputs = []\n",
        "for emb_list in df['sentence_embeddings']:\n",
        "    sentence_embs = torch.tensor(np.array(emb_list))\n",
        "    if len(sentence_embs.shape) == 2:\n",
        "        sentence_embs = sentence_embs.unsqueeze(0)\n",
        "    weighted_sum, _ = sentence_attention(sentence_embs)\n",
        "    sentence_attention_outputs.append(weighted_sum.detach().numpy())\n"
      ],
      "metadata": {
        "id": "RIbJgaisrXrd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ACzHfpOgrX9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings = []\n",
        "for doc2vec_emb, sentence_attn_emb in zip(doc2vec_embeddings, sentence_attention_outputs):\n",
        "    sentence_attn_emb_flat = sentence_attn_emb.flatten()\n",
        "    combined_embedding = np.concatenate((doc2vec_emb, sentence_attn_emb_flat))\n",
        "    combined_embeddings.append(combined_embedding)\n",
        "\n",
        "X = np.array(combined_embeddings)\n",
        "y = df['labels'].values\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "pxMhnE1YrYSz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lmL3-Ubvrjym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ADR1XDeNzSiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an adjusted Bi-LSTM model with two layers and reduced dropout\n",
        "class AdjustedBiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_prob=0.1):\n",
        "        super(AdjustedBiLSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=2, bidirectional=True, batch_first=True, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_out = lstm_out[:, 0, :]  # Only use the first time step\n",
        "        logits = self.fc(lstm_out)\n",
        "        return self.softmax(logits)\n",
        "\n",
        "# Initialize model with weight decay for L2 regularization and no dropout\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "output_dim = 2\n",
        "model = AdjustedBiLSTMClassifier(input_dim, hidden_dim, output_dim, dropout_prob=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
        "\n",
        "# Training loop with early stopping\n",
        "best_val_accuracy = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    inputs = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add sequence dimension\n",
        "    labels = torch.tensor(y_train, dtype=torch.long)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_inputs = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
        "        val_labels = torch.tensor(y_val, dtype=torch.long)\n",
        "        val_outputs = model(val_inputs)\n",
        "        _, val_predicted = torch.max(val_outputs, 1)\n",
        "        val_accuracy = accuracy_score(val_labels.numpy(), val_predicted.numpy())\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        wait = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Load the best model for final evaluation\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "evaluate(X_train, y_train, \"Training Set\")\n",
        "evaluate(X_val, y_val, \"Validation Set\")\n",
        "evaluate(X_test, y_test, \"Test Set\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByhsV3S8zS8W",
        "outputId": "9502fda5-d0fa-4ad0-a629-7075ef7f3d00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.6848, Validation Accuracy: 70.97%\n",
            "Epoch 2/50, Loss: 0.6341, Validation Accuracy: 71.61%\n",
            "Epoch 3/50, Loss: 0.5867, Validation Accuracy: 72.73%\n",
            "Epoch 4/50, Loss: 0.5423, Validation Accuracy: 74.33%\n",
            "Epoch 5/50, Loss: 0.5007, Validation Accuracy: 77.32%\n",
            "Epoch 6/50, Loss: 0.4607, Validation Accuracy: 79.88%\n",
            "Epoch 7/50, Loss: 0.4178, Validation Accuracy: 83.67%\n",
            "Epoch 8/50, Loss: 0.3719, Validation Accuracy: 86.18%\n",
            "Epoch 9/50, Loss: 0.3348, Validation Accuracy: 87.94%\n",
            "Epoch 10/50, Loss: 0.3230, Validation Accuracy: 87.73%\n",
            "Epoch 11/50, Loss: 0.3143, Validation Accuracy: 88.10%\n",
            "Epoch 12/50, Loss: 0.2970, Validation Accuracy: 88.05%\n",
            "Epoch 13/50, Loss: 0.2903, Validation Accuracy: 87.89%\n",
            "Epoch 14/50, Loss: 0.2931, Validation Accuracy: 88.37%\n",
            "Epoch 15/50, Loss: 0.2895, Validation Accuracy: 88.63%\n",
            "Epoch 16/50, Loss: 0.2779, Validation Accuracy: 89.27%\n",
            "Epoch 17/50, Loss: 0.2679, Validation Accuracy: 89.17%\n",
            "Epoch 18/50, Loss: 0.2652, Validation Accuracy: 89.49%\n",
            "Epoch 19/50, Loss: 0.2579, Validation Accuracy: 89.70%\n",
            "Epoch 20/50, Loss: 0.2478, Validation Accuracy: 90.18%\n",
            "Epoch 21/50, Loss: 0.2415, Validation Accuracy: 89.81%\n",
            "Epoch 22/50, Loss: 0.2390, Validation Accuracy: 90.02%\n",
            "Epoch 23/50, Loss: 0.2356, Validation Accuracy: 90.66%\n",
            "Epoch 24/50, Loss: 0.2277, Validation Accuracy: 91.20%\n",
            "Epoch 25/50, Loss: 0.2212, Validation Accuracy: 91.36%\n",
            "Epoch 26/50, Loss: 0.2176, Validation Accuracy: 91.41%\n",
            "Epoch 27/50, Loss: 0.2101, Validation Accuracy: 91.57%\n",
            "Epoch 28/50, Loss: 0.2006, Validation Accuracy: 91.84%\n",
            "Epoch 29/50, Loss: 0.1934, Validation Accuracy: 91.89%\n",
            "Epoch 30/50, Loss: 0.1867, Validation Accuracy: 92.48%\n",
            "Epoch 31/50, Loss: 0.1786, Validation Accuracy: 92.74%\n",
            "Epoch 32/50, Loss: 0.1729, Validation Accuracy: 93.28%\n",
            "Epoch 33/50, Loss: 0.1677, Validation Accuracy: 93.38%\n",
            "Epoch 34/50, Loss: 0.1602, Validation Accuracy: 93.06%\n",
            "Epoch 35/50, Loss: 0.1576, Validation Accuracy: 93.49%\n",
            "Epoch 36/50, Loss: 0.1520, Validation Accuracy: 93.70%\n",
            "Epoch 37/50, Loss: 0.1501, Validation Accuracy: 93.86%\n",
            "Epoch 38/50, Loss: 0.1458, Validation Accuracy: 93.65%\n",
            "Epoch 39/50, Loss: 0.1449, Validation Accuracy: 94.02%\n",
            "Epoch 40/50, Loss: 0.1413, Validation Accuracy: 94.29%\n",
            "Epoch 41/50, Loss: 0.1403, Validation Accuracy: 94.29%\n",
            "Epoch 42/50, Loss: 0.1348, Validation Accuracy: 94.34%\n",
            "Epoch 43/50, Loss: 0.1334, Validation Accuracy: 94.66%\n",
            "Epoch 44/50, Loss: 0.1305, Validation Accuracy: 94.77%\n",
            "Epoch 45/50, Loss: 0.1286, Validation Accuracy: 94.66%\n",
            "Epoch 46/50, Loss: 0.1261, Validation Accuracy: 94.88%\n",
            "Epoch 47/50, Loss: 0.1246, Validation Accuracy: 94.82%\n",
            "Epoch 48/50, Loss: 0.1213, Validation Accuracy: 95.25%\n",
            "Epoch 49/50, Loss: 0.1205, Validation Accuracy: 95.30%\n",
            "Epoch 50/50, Loss: 0.1185, Validation Accuracy: 95.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-fa105e2332ed>:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Set Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-Functional       0.97      0.95      0.96      4862\n",
            "    Functional       0.94      0.96      0.95      3884\n",
            "\n",
            "      accuracy                           0.96      8746\n",
            "     macro avg       0.96      0.96      0.96      8746\n",
            "  weighted avg       0.96      0.96      0.96      8746\n",
            "\n",
            "Training Set Accuracy: 95.88%\n",
            "\n",
            "Validation Set Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-Functional       0.97      0.94      0.96      1045\n",
            "    Functional       0.93      0.97      0.95       829\n",
            "\n",
            "      accuracy                           0.95      1874\n",
            "     macro avg       0.95      0.95      0.95      1874\n",
            "  weighted avg       0.95      0.95      0.95      1874\n",
            "\n",
            "Validation Set Accuracy: 95.30%\n",
            "\n",
            "Test Set Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-Functional       0.97      0.93      0.95      1036\n",
            "    Functional       0.92      0.96      0.94       839\n",
            "\n",
            "      accuracy                           0.94      1875\n",
            "     macro avg       0.94      0.95      0.94      1875\n",
            "  weighted avg       0.95      0.94      0.94      1875\n",
            "\n",
            "Test Set Accuracy: 94.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6JVY40CCzSNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XYcomGsBzSA-"
      }
    }
  ]
}